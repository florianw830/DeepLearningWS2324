{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyGame Snake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einführung\n",
    "Das klassische Spiel \"Snake\" ist ein einfaches Videospiel, welches auf Personal-Computern zuerst im Jahr 1978 von  Peter Trefonas unter dem Namen \"Worm\" auf dem TRS-80 implementiert wurde [1]. Seitdem hat es zahlreiche Iterationen und Variationen erfahren. Das Spielprinzip ist einfach, aber mit fortschreitender Spieldauer immer anspruchsvoller. Aufgrund seiner hohen bekanntheit (früher und heute) kann es als zeitloser Klassiker bezeichnet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spielprinzip\n",
    "Das Hauptziel des Spiels besteht darin, eine Schlange durch ein begrenztes Spielfeld zu steuern und dabei so viele Nahrungsmittel wie möglich zu fressen. Mit jedem verzehrten Nahrungsmittel wächst die Schlange, was das Spiel den Schwierigkeitsgrad kontinuirlich erhöht. Eine Berührung einer der Wände oder des Körpers der Schlange führt zum Spielende."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herausforderungen\n",
    "Der Spieler benötigt Geschicklichkeit und strategisches Denken, um optimale Entscheidungen in Echtzeit zu treffen. Es muss vorrausschauend geplant werden, um die Schlange sicher durch das Spielfeld zu führen und gleichzeitig die wachsende Länge der Schlange beachtet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ziel der Untersuchung\n",
    "Im folgenden werden verschiedene KI Modelle darauf trainiert, das Spiel Snake zu meistern. Der Fokus liegt auf der Anwendung verschiedener Deep Learning-Verfahren, um die Leistung der KI-Modelle zu vergleichen. Diese Modelle werden darauf trainiert, intelligente Entscheidungen zu treffen, um die Schlange effektiv zu steuern und dabei möglichst viele Nahrungsmittel zu fressen. \n",
    "\n",
    "Außerdem soll untersucht werden, wie einfach fertig trainierte Modelle an geänderte Spielregeln angepasst werden können. Dabei sollen die Modelle zunächst auf das klassiche Spiel Snake trainiert werden und danach auf Varianten von Snake mit geänderten Regeln angwandt werden. Folgende Regelanpassungen sind vorgesehen:\n",
    "- Weitere Hindernisse auf dem Spielfeld\n",
    "- Nahrungsmittel mit Verschiedenen Punktzahlen, die gleichzeitig erscheinen\n",
    "- Maximale Dauer zwischen zwei Nahrungsaufnahmen\n",
    "- Keine Wände am Bildschirmrand\n",
    "\n",
    "Der Vergleich der verschiedenen Ansätze ermöglicht Einblicke in die Wirksamkeit unterschiedlicher Deep Learning-Techniken bei der Bewältigung von komplexen Aufgaben und deren Adaptionsfähigkeit auf geänderte Problemstellungen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verfahren\n",
    "In der Arbeit werden die folgenden drei Verfahren untersucht. Sie werden im Folgenden kurz vorgestellt.  \n",
    "Einige Verfahren nutzen sogenannte Agenten. Das bedeutet, dass das jeweilige Verfahren auf das gestellte Problem angewendet wird.\n",
    "### Deep Q-Networks/Deep Q-Learning\n",
    "Deep Q-Learning (DQL) ist eine Methode, die auf künstlichen neuronalen Netzwerken basiert und dazu dient, komplexe Entscheidungsprozesse zu erlernen.Dabei werden tiefe neuronale Netzwerke mit dem sogenanten Q-Learning, einer Methode des verstärkenden lernens, kombiniert.\n",
    "> \"Q-Learning ist eine Form des zeitlichen Differenzlernens. Als solches ist es eine modellfreie Verstärkungslernmethode, die Elemente der dynamischen Programmierung mit Monte-Carlo-Schätzungen kombiniert. Unter anderem aufgrund des Beweises von Watkins (1989), dass es zur optimalen Wertfunktion konvergiert, gehört das Q-Learning zu den am häufigsten verwendeten und bekanntesten Verstärkungslernalgorithmen.\" [2, S. 1033]  \n",
    "\n",
    "\n",
    "Der Kern des Q-Learning ist die Aktionswert-Funktion Q(s,a). Diese Funktion gibt den Ertrag für eine Aktion a aus, die von einem Agenten im Zustand s ausgeführt wird [3]. \n",
    "Die Ergebnisse der Aktionswert-Funktion werden in der Q-Tabelle gespeichert. \n",
    "Der gesamte Algorithmus lässt sich wie folgt beschreiben:\n",
    "1. Die Q-Tabelle wird mit zufälligen Werten (oder nullen) initialisiert.\n",
    "2. Der Agent interagiert mit der Umgebung und erhält das Tuple (s,a,r,s')  \n",
    "Zustand (s), Aktion (a), Ertrag (r), Folgezustand (s'). Dabei wird auch die Entscheidung getroffen, welche Aktion als nächstes durchgeführt wird. Diese Entscheidungsfindung ist ein Dilemma zwischen Erkundung und Ausbeutung (exploration and exploitation)[4, S. 127] und lässt sich nicht eindeutig lösen.\n",
    "3. Der Ertrag wird in die Q-Tabelle aufgenommen. Dieser Errechnet sich wie folgt  \n",
    "Q(s,a) = r + $\\gamma$  $max_{a' \\in A}(Q(s',a'))$\n",
    "4. Schritte zwei und drei wiederholen.  \n",
    "[4, S.121]\n",
    "### Reinforcement Learning \n",
    "### Deep Policy Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung und Vorgehen\n",
    "Das eigentliche Spiel ist als Klasse implementiert, so dass mehrere Ausführungen gleichzeitig möglich sind. Die Darstellung des Spiels erfolgt mit dem PyGame Framwork[99]. Für eine effiziente Berechung während des Trainings eines Machine Learning Modells muss das Rendering jedoch abschaltbar sein. Außerdem ist es notwendig, dass das Spiel mit hoher Geschwindigkeit läuft. Auch dies ist für ein effektives Training notwendig und möglich, da ein Computer nicht den gleichen Einschränkungen der Reaktionszeit unterliegt wie ein Mensch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.9.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random as rnd\n",
    "import pygame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,pg):\n",
    "        self.pg = pg\n",
    "    def tick(self, head_position, tails, target, target_points):\n",
    "        keys = [False]*512\n",
    "        return keys\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent): \n",
    "    def tick(self, head_position, tails, target, target_points):\n",
    "        keys = [False]*512\n",
    "        if rnd.randint(0,100) <30:\n",
    "            keys[rnd.choice([pygame.K_w,pygame.K_a,pygame.K_s,pygame.K_d])] = True\n",
    "        return keys\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(a,b):\n",
    "    return math.sqrt( (a.y-b.y) ** 2 + (a.x-b.x) ** 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m                 pygame\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m     15\u001b[0m         pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 15\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m pygame\u001b[38;5;241m.\u001b[39mQUIT:\n\u001b[0;32m     12\u001b[0m         pygame\u001b[38;5;241m.\u001b[39mquit()\n\u001b[1;32m---> 15\u001b[0m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global SCREEN, CLOCK\n",
    "    pg = pygame.init()\n",
    "    SCREEN = pygame.display.set_mode((1280, 720))\n",
    "    CLOCK = pygame.time.Clock()\n",
    "    SCREEN.fill(BLACK)\n",
    "\n",
    "    while True:\n",
    "        draw_grid(1280, 720,20,SCREEN)\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                \n",
    "\n",
    "        pygame.display.update()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnakeGame():\n",
    "    BLACK = (0, 0, 0)\n",
    "    WHITE = (200, 200, 200)\n",
    "\n",
    "    def __init__(self,render_game,agent,screen_width,screen_height,speed_factor):\n",
    "        self.render_game = render_game\n",
    "        self.agent_game = not agent == None\n",
    "        self.agent = agent\n",
    "        self.screen_width = screen_width\n",
    "        self.screen_height = screen_height\n",
    "        self.speed_factor = speed_factor\n",
    "        self.screen =None\n",
    "        self.clock = None\n",
    "        self.block_size =20\n",
    "        self.snake = [(screen_width // 2*self.block_size, screen_height // 2*self.block_size)]\n",
    "        \n",
    "        if render_game:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "            self.clock  = pygame.time.Clock()\n",
    "    #def run_game(self):\n",
    "        \n",
    "    def handle_input(self):\n",
    "        if(self.agent_game):\n",
    "            keys = self.agent.tick(None,None,None,None)    \n",
    "        else:\n",
    "            keys = pygame.key.get_pressed()\n",
    "        return keys\n",
    "    def draw_grid(self):\n",
    "        for x in range(0,self.screen_width,self.block_size):\n",
    "            for y in range(0, self.screen_height, self.block_size):\n",
    "                rct = pygame.Rect(x,y,self.block_size,selfblock_size)\n",
    "                pygame.draw.rect(self.screen,WHITE,rct,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pygame.org/docs/\n",
    "# Example file showing a circle moving on screen\n",
    "render_game = True\n",
    "agent_game = True\n",
    "screen_width = 1280\n",
    "screen_height = 720\n",
    "\n",
    "speed_factor = 3\n",
    "\n",
    "# pygame setup\n",
    "pygame.init()\n",
    "agt = RandomAgent(pygame)\n",
    "if render_game:\n",
    "    screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "clock = pygame.time.Clock()\n",
    "running = True\n",
    "\n",
    "dt = 0\n",
    "\n",
    "pygame.font.init() # you have to call this at the start, \n",
    "                   # if you want to use this module.\n",
    "my_font = pygame.font.SysFont('Arial', 30)\n",
    "\n",
    "player_pos = pygame.Vector2(screen_width / 2, screen_height / 2)\n",
    "tails=[]\n",
    "tail_length =1\n",
    "player_dest_y = 100\n",
    "player_dest_x = 0\n",
    "\n",
    "points =0\n",
    "ct=0\n",
    "random_obj = pygame.Vector2(rnd.randint(0,screen_width), rnd.randint(0,screen_height))   \n",
    "text_surface = my_font.render(f'Points {points}', False, (0, 0, 0))\n",
    "\n",
    "while running:\n",
    "    if render_game:\n",
    "        screen.blit(text_surface, (0,0))\n",
    "    # poll for events\n",
    "    # pygame.QUIT event means the user clicked X to close your window\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "    \n",
    "    #dst = math.sqrt( (player_pos.y-random_obj.y) ** 2 + (player_pos.x-random_obj.x) ** 2 )\n",
    "    \n",
    "    dst = get_distance(player_pos,random_obj) \n",
    "    if dst < 80:\n",
    "        rnd.randint(0,screen.get_width())\n",
    "        random_obj = pygame.Vector2(rnd.randint(0,screen_width), rnd.randint(0,screen_height))   \n",
    "        tail_length+=1\n",
    "        points+=1\n",
    "        text_surface = my_font.render(f'Points {points}', False, (0, 0, 0))\n",
    "\n",
    "    if (screen_width <= player_pos.x or screen_height <= player_pos.y \n",
    "        or  player_pos.x <=0 or player_pos.y <=0) :\n",
    "        break\n",
    "\n",
    "    if render_game:\n",
    "        screen.fill(\"purple\")\n",
    "\n",
    "        pygame.draw.circle(screen, \"red\", player_pos, 40)\n",
    "        for t in tails:\n",
    "            pygame.draw.circle(screen, \"red\", t, 40)\n",
    "        pygame.draw.circle(screen, \"blue\", random_obj, 40)\n",
    "\n",
    "    \n",
    "    if(agent_game):\n",
    "        keys = agt.tick(None,None,None,None)    \n",
    "    else:\n",
    "        keys = pygame.key.get_pressed()\n",
    "    \n",
    "    if keys[pygame.K_w]:\n",
    "        player_dest_y,player_dest_x = -100,0\n",
    "    elif keys[pygame.K_s]:\n",
    "        player_dest_y,player_dest_x = 100,0\n",
    "    elif keys[pygame.K_a]:\n",
    "        player_dest_y,player_dest_x = 0,-100\n",
    "    elif keys[pygame.K_d]:\n",
    "        player_dest_y,player_dest_x = 0,100\n",
    "\n",
    "    ct+=1\n",
    "    if ct%(30//speed_factor) == 0:\n",
    "        tails.append(player_pos.copy())\n",
    "        ct=0\n",
    "\n",
    "    if len(tails) > tail_length:\n",
    "        tails = tails[-tail_length:]\n",
    "    player_pos.y += player_dest_y* dt\n",
    "    player_pos.x += player_dest_x * dt    \n",
    "    end_game = False\n",
    "    for t in tails[:-1]:\n",
    "        if get_distance(t,player_pos)< 5:\n",
    "            end_game =True\n",
    "            break\n",
    "\n",
    "    if end_game:\n",
    "        break\n",
    "\n",
    "    if render_game:\n",
    "        pygame.display.flip()\n",
    "\n",
    "    # limits FPS to 60\n",
    "    # dt is delta time in seconds since last frame, used for framerate-\n",
    "    # independent physics.\n",
    "    dt = clock.tick(60) /(1000//speed_factor)\n",
    "\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literatur:\n",
    "[1]: \"Snake (Computerspiel)\", [Online] Verfügbar: https://de.wikipedia.org/w/index.php?title=Snake_(Computerspiel)&oldid=236710907 , Abgerufen 13.01.2023  \n",
    "[2]:  Sammut, Claude; Webb, Geoffrey I., \"Encyclopedia of machine learning and data mining\", 2017, Springer, ISBN: 9781489976871  \n",
    "[3]: Artem Oppermann, \"Deep Q-Learning\", [Online] Verfügbar: https://artemoppermann.com/de/deep-q-learning/ , Abgerufen 13.01.2023  \n",
    "[4]:  Lapan, Maxim, \"Deep reinforcement learning hands-on\", 2018, Packt, ISBN: 978-1-78883-424-7  \n",
    "[99]: https://www.pygame.org/ ,Abgerufen 10.01.2023  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Stretch/Untouched | ProbDistribution | Accuracy |\n",
    "| --- | --- | --- |\n",
    "| Stretched | Gaussian | .843 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
